{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a Spam Filter with Naive Bayes\n",
    "<p>We want to build a spam filter using naive Bayes. First, we need to \"teach\" the computer how to classify messages. In ordert to do that, we will use the nultinomial Naive Bayes algorithm along with a dataset of 5,572 text messages, which have been already classified by humans.</p>\n",
    "<p>The dataset can be found <a href = \"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\">here</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_collection = pd.read_csv('SMSSpamCollection', \n",
    "                              sep = '\\t', \n",
    "                              header = None, \n",
    "                              names = ['Label','SMS']\n",
    "                             )\n",
    "spam_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, the file is too big for the DataQuest server. Hence, I will decrease the number of SMS messages here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_collection = spam_collection.sample(n = 3000)\n",
    "spam_collection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The label \"ham\" refers to \"not-spam\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label    0\n",
       "SMS      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_collection.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.862667\n",
       "spam    0.137333\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_collection.groupby('Label').size()/spam_collection.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will split into a training and a test set: 80% of the data into the training set and 20% into the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_random = spam_collection.sample(frac = 1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "index = round(spam_collection.shape[0]*0.8)\n",
    "spam_train = spam_random[:index].reset_index(drop=True)\n",
    "spam_test = spam_random[index:].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Where wuld I be without my baby? The thought a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dear Voucher Holder, 2 claim this weeks offer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>But you dint in touch with me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hai priya are you right. What doctor said pa. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>K come to nordstrom when you're done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Where wuld I be without my baby? The thought a...\n",
       "1  spam  Dear Voucher Holder, 2 claim this weeks offer,...\n",
       "2   ham                     But you dint in touch with me.\n",
       "3   ham  Hai priya are you right. What doctor said pa. ...\n",
       "4   ham               K come to nordstrom when you're done"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning:\n",
    "<p>To understand and quantify the data, we sort and count each word: a dataframe (SMS x words) in which we quantify how often each word occurs in each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want some cock  My hubby s away  I need a real man 2 satisfy me  Txt WIFE to 89938 for no strings action   Txt STOP 2 end  txt rec  1 50ea  OTBox 731 LA1 7WS   '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('\\W',' ',spam_train['SMS'].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "spam_train['SMS'] = spam_train['SMS'].apply(lambda x: re.sub('\\W',' ',x)).str.lower()\n",
    "spam_train['SMS'] = spam_train['SMS'].apply(lambda x: re.sub('  ',' ',x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>although i told u dat i m into baig face watch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>i want some cock my hubby s away i need a real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>1 go to write msg 2 put on dictionary mode 3 c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>she doesnt need any test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>okie but i scared u say i fat  then u dun wan ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  although i told u dat i m into baig face watch...\n",
       "1  spam  i want some cock my hubby s away i need a real...\n",
       "2   ham  1 go to write msg 2 put on dictionary mode 3 c...\n",
       "3   ham                          she doesnt need any test \n",
       "4   ham  okie but i scared u say i fat  then u dun wan ..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to create the vocabulary: a list with all unique words used in the SMS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "for sms in spam_train['SMS'].str.split():\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "        \n",
    "vocabulary = list(set(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5582"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['syria',\n",
       " 'madam',\n",
       " 'cheat',\n",
       " 'overemphasise',\n",
       " '4my',\n",
       " 'freefone',\n",
       " 'stop',\n",
       " 'guoyang',\n",
       " 'decide',\n",
       " 'tcs',\n",
       " 'weight',\n",
       " 'ukp',\n",
       " 'vary',\n",
       " 'app',\n",
       " 'joining',\n",
       " 'askd',\n",
       " 'lately',\n",
       " 'lacs',\n",
       " 'my',\n",
       " 'opted',\n",
       " '2nite',\n",
       " 'thesis',\n",
       " 'tones2you',\n",
       " 'mayb',\n",
       " 'mrng',\n",
       " 'dancce',\n",
       " 'phb1',\n",
       " 'rael',\n",
       " 'gets',\n",
       " '45239',\n",
       " 'spending',\n",
       " 'quit',\n",
       " 'satthen',\n",
       " '0871212025016',\n",
       " 'action',\n",
       " 'text',\n",
       " 'university',\n",
       " 'early',\n",
       " '12',\n",
       " '9t',\n",
       " '31',\n",
       " 'mail',\n",
       " 'yesterday',\n",
       " 'o2',\n",
       " 'cheap',\n",
       " '8800',\n",
       " 'lyrics',\n",
       " 'only',\n",
       " 'basket',\n",
       " 'statement',\n",
       " 'devouring',\n",
       " 'ummma',\n",
       " 'rocks',\n",
       " 'cum',\n",
       " 'awkward',\n",
       " 'happiness',\n",
       " 'inclu',\n",
       " 'selected',\n",
       " 'sends',\n",
       " '2stoptxt',\n",
       " 'cardiff',\n",
       " 'call09050000327',\n",
       " 'yelow',\n",
       " 'stupid',\n",
       " 'witout',\n",
       " 'quiet',\n",
       " 'from',\n",
       " 'litres',\n",
       " '08719899229',\n",
       " 'wtf',\n",
       " 'bognor',\n",
       " 'various',\n",
       " 'patty',\n",
       " 'malaria',\n",
       " 'concert',\n",
       " 'beforehand',\n",
       " 'latest',\n",
       " 'aa',\n",
       " 'espe',\n",
       " 'cops',\n",
       " 'liver',\n",
       " 'tirunelvali',\n",
       " 'little',\n",
       " 'cd',\n",
       " 'happier',\n",
       " 'studentfinancial',\n",
       " 'pretsorginta',\n",
       " 'energy',\n",
       " 'decimal',\n",
       " 'q',\n",
       " 'texted',\n",
       " 'ic',\n",
       " '200p',\n",
       " 'wid',\n",
       " 'erm',\n",
       " 'bell',\n",
       " 'avenge',\n",
       " 'masteriastering',\n",
       " 'country',\n",
       " 'mark',\n",
       " 'way2sms',\n",
       " 'corrct',\n",
       " 'meaning',\n",
       " 'web2mobile',\n",
       " 'upstairs',\n",
       " '09061701851',\n",
       " 'isnt',\n",
       " 'colours',\n",
       " 'food',\n",
       " 'srsly',\n",
       " 'julianaland',\n",
       " 'however',\n",
       " '09050000332',\n",
       " 'arise',\n",
       " 'making',\n",
       " 'oblisingately',\n",
       " 'ax',\n",
       " 'traditions',\n",
       " 'small',\n",
       " 'menu',\n",
       " 'elsewhere',\n",
       " 'feel',\n",
       " 'whore',\n",
       " 'completed',\n",
       " '0quit',\n",
       " 'gn',\n",
       " 'nhs',\n",
       " 'lunch',\n",
       " 'arrange',\n",
       " 'luck',\n",
       " 'faggy',\n",
       " 'burrito',\n",
       " '4',\n",
       " 'mnth',\n",
       " 'boundaries',\n",
       " 'educational',\n",
       " '08081560665',\n",
       " 'savings',\n",
       " 'extra',\n",
       " 'sofa',\n",
       " 'genuine',\n",
       " 'w45wq',\n",
       " 'holding',\n",
       " '09061104276',\n",
       " 'were',\n",
       " 'sumthin',\n",
       " 'transfered',\n",
       " 'side',\n",
       " 'embarassed',\n",
       " 'usf',\n",
       " 'chef',\n",
       " 'configure',\n",
       " 'proze',\n",
       " 'establish',\n",
       " 'relaxing',\n",
       " 'rcvd',\n",
       " 'install',\n",
       " 'tuition',\n",
       " 'gaps',\n",
       " 'custom',\n",
       " '84484',\n",
       " 'burial',\n",
       " 'arrested',\n",
       " 'nigpun',\n",
       " 'turned',\n",
       " 'sutra',\n",
       " 'stories',\n",
       " 'minus',\n",
       " 'doing',\n",
       " '087104711148',\n",
       " 'wonder',\n",
       " 'bishan',\n",
       " 'wonderful',\n",
       " '2mro',\n",
       " 'tuth',\n",
       " 'month',\n",
       " 'tim',\n",
       " 'named',\n",
       " 'chaps',\n",
       " 'dressed',\n",
       " 'least',\n",
       " 'mention',\n",
       " 'time',\n",
       " 'spk',\n",
       " 'able',\n",
       " 'appreciate',\n",
       " 'rs',\n",
       " 'f',\n",
       " 'rents',\n",
       " 'motor',\n",
       " 'saying',\n",
       " 'parents',\n",
       " 'wind',\n",
       " 'hell',\n",
       " '36504',\n",
       " '2lands',\n",
       " 'books',\n",
       " 'lifeis',\n",
       " 'recovery',\n",
       " 'bluff',\n",
       " 'pride',\n",
       " 'her',\n",
       " 'granite',\n",
       " 'benefits',\n",
       " 'tired',\n",
       " 'million',\n",
       " 'stopped',\n",
       " 'rum',\n",
       " 'jordan',\n",
       " 'gives',\n",
       " 'w',\n",
       " 'preschoolco',\n",
       " 'unredeemed',\n",
       " 'hotel',\n",
       " 'shitinnit',\n",
       " 'window',\n",
       " 'birds',\n",
       " 'probs',\n",
       " 'ignorant',\n",
       " 'bt',\n",
       " 'rajnikant',\n",
       " '373',\n",
       " 'answr',\n",
       " 'subscribe',\n",
       " 'listed',\n",
       " 'sophas',\n",
       " 'cal',\n",
       " '08712400200',\n",
       " 'main',\n",
       " 'congratulation',\n",
       " 'omw',\n",
       " 'd',\n",
       " 'video',\n",
       " 'spoilt',\n",
       " 'aco',\n",
       " 'tmorrow',\n",
       " '0808',\n",
       " 'reassurance',\n",
       " 'humanities',\n",
       " 'canada',\n",
       " 'pocketbabe',\n",
       " 'nitros',\n",
       " 'norcorp',\n",
       " 'archive',\n",
       " 'gorgeous',\n",
       " 'miiiiiiissssssssss',\n",
       " 'tog',\n",
       " 'morphine',\n",
       " 'shocking',\n",
       " 'towards',\n",
       " 'relax',\n",
       " 'regret',\n",
       " 'soft',\n",
       " 'arm',\n",
       " 'trained',\n",
       " 'saucy',\n",
       " 'cruel',\n",
       " 'id',\n",
       " '000',\n",
       " 'ts',\n",
       " 'song',\n",
       " 'mi',\n",
       " 'box61',\n",
       " 'spree',\n",
       " 'tms',\n",
       " 'specially',\n",
       " 'rest',\n",
       " 'ear',\n",
       " 'shattered',\n",
       " 'personality',\n",
       " 'm263uz',\n",
       " 'christmas',\n",
       " 'envy',\n",
       " 'matches',\n",
       " 'somewheresomeone',\n",
       " 'vijay',\n",
       " 'mins',\n",
       " 'teasing',\n",
       " 'doors',\n",
       " 'neva',\n",
       " 'cruise',\n",
       " 'surprised',\n",
       " 'unable',\n",
       " 'evening',\n",
       " 'bluetooth',\n",
       " 'foned',\n",
       " 'peace',\n",
       " 'friendship',\n",
       " 'scenario',\n",
       " 'num',\n",
       " 'cuck',\n",
       " 'z',\n",
       " 'servs',\n",
       " 'fullonsms',\n",
       " 'cashed',\n",
       " 'wish',\n",
       " 'poker',\n",
       " 'tescos',\n",
       " 'black',\n",
       " 'pears',\n",
       " 'bet',\n",
       " 'dload',\n",
       " 'joke',\n",
       " 'astoundingly',\n",
       " '09066350750',\n",
       " 'va',\n",
       " 'dads',\n",
       " 'jeremiah',\n",
       " 'cha',\n",
       " 'cya',\n",
       " 'copies',\n",
       " 'tnc',\n",
       " 'noe',\n",
       " 'leaving',\n",
       " 'accenture',\n",
       " 'rush',\n",
       " 'jiayin',\n",
       " '09058094565',\n",
       " 'ente',\n",
       " 'confused',\n",
       " 'seeing',\n",
       " 'newest',\n",
       " 'havbeen',\n",
       " 'step',\n",
       " 'sayy',\n",
       " 'ringtoneking',\n",
       " 'beg',\n",
       " 'few',\n",
       " 'keeps',\n",
       " 'csbcm4235wc1n3xx',\n",
       " 'games',\n",
       " 'perfect',\n",
       " 'eatin',\n",
       " 'thot',\n",
       " 'lightly',\n",
       " 'removed',\n",
       " 'srt',\n",
       " 'yay',\n",
       " 'blanked',\n",
       " 'popcorn',\n",
       " 'dozens',\n",
       " 'stream',\n",
       " 'ain',\n",
       " 'il',\n",
       " 'marley',\n",
       " 'jas',\n",
       " 'hasn',\n",
       " 'share',\n",
       " 'dentists',\n",
       " 'matured',\n",
       " 'list',\n",
       " 'poop',\n",
       " 'mad2',\n",
       " 'mesages',\n",
       " 'lovable',\n",
       " '18p',\n",
       " 'uk',\n",
       " 'bimbo',\n",
       " '10am',\n",
       " 'getzed',\n",
       " 'there',\n",
       " '01223585236',\n",
       " 'chatter',\n",
       " 'expensive',\n",
       " 'tech',\n",
       " 'image',\n",
       " 'zouk',\n",
       " 'bills',\n",
       " 'ipads',\n",
       " 'musicnews',\n",
       " '08717507382',\n",
       " 'august',\n",
       " 'u4',\n",
       " 'cock',\n",
       " 'janx',\n",
       " 'keys',\n",
       " '87575',\n",
       " 'sake',\n",
       " 'spin',\n",
       " 'use',\n",
       " 'passable',\n",
       " 'completes',\n",
       " 'february',\n",
       " 'sed',\n",
       " 'line',\n",
       " 'promoting',\n",
       " 'inconvenient',\n",
       " 'amused',\n",
       " '700',\n",
       " 'lemme',\n",
       " 'credits',\n",
       " 'rayan',\n",
       " 'interviews',\n",
       " 'mmmmm',\n",
       " 'fml',\n",
       " 'supposed',\n",
       " 'vibrate',\n",
       " 'ha',\n",
       " '1cup',\n",
       " 'pls',\n",
       " '86688',\n",
       " 'superb',\n",
       " 'fav',\n",
       " 'accounts',\n",
       " 'goes',\n",
       " 'laughed',\n",
       " 'experiment',\n",
       " 'cr01327bt',\n",
       " 'ahhh',\n",
       " '09061790126',\n",
       " 'mandan',\n",
       " 'necesity',\n",
       " 'clear',\n",
       " '82050',\n",
       " 'drunken',\n",
       " 'alaikkum',\n",
       " 'swayze',\n",
       " 'slo',\n",
       " 'uncle',\n",
       " 'enter',\n",
       " 'maniac',\n",
       " 'salary',\n",
       " 'bid',\n",
       " '09065171142',\n",
       " 'changes',\n",
       " 'friend',\n",
       " 'players',\n",
       " 'card',\n",
       " 'jaykwon',\n",
       " 'gr8prizes',\n",
       " 'prizes',\n",
       " 'nammanna',\n",
       " '29',\n",
       " 'dileep',\n",
       " 'height',\n",
       " 'bottle',\n",
       " 'drivby',\n",
       " 'sw73ss',\n",
       " '02',\n",
       " 'gautham',\n",
       " 'tears',\n",
       " 'goverment',\n",
       " 'excellent',\n",
       " 'lady',\n",
       " 'events',\n",
       " 'culdnt',\n",
       " 'wisheds',\n",
       " 'overtime',\n",
       " 'word',\n",
       " 'replacement',\n",
       " '07734396839',\n",
       " 'cute',\n",
       " 'pre',\n",
       " 'understood',\n",
       " 's',\n",
       " 'browser',\n",
       " 'cornwall',\n",
       " 'results',\n",
       " 'herself',\n",
       " 'payasam',\n",
       " 'munsters',\n",
       " 'babysit',\n",
       " 'decision',\n",
       " 'sim',\n",
       " 'cuddle',\n",
       " 'mob',\n",
       " '08006344447',\n",
       " 'maturity',\n",
       " '8077',\n",
       " 'colleg',\n",
       " 'cocksuckers',\n",
       " 'searching',\n",
       " 'meaningless',\n",
       " 'honest',\n",
       " 'happiest',\n",
       " 'stop2stop',\n",
       " 'logo',\n",
       " 'hardcore',\n",
       " '087123002209am',\n",
       " 'in2',\n",
       " 'chat80155',\n",
       " 'mel',\n",
       " 'tour',\n",
       " 'romantic',\n",
       " 'w4',\n",
       " 'infernal',\n",
       " 'sk38xh',\n",
       " 'abeg',\n",
       " 'vry',\n",
       " 'lor',\n",
       " 'fals',\n",
       " 'bb',\n",
       " 'kappa',\n",
       " 'unsecured',\n",
       " 'called',\n",
       " 'rough',\n",
       " 'barely',\n",
       " 'gaytextbuddy',\n",
       " 'sang',\n",
       " 'filled',\n",
       " 'waht',\n",
       " 'bless',\n",
       " 'prolly',\n",
       " 'tot',\n",
       " 'red',\n",
       " 'fancy',\n",
       " 'leafcutter',\n",
       " 'internet',\n",
       " 'esplanade',\n",
       " 'ur',\n",
       " 'drops',\n",
       " 'supply',\n",
       " 'stopsms',\n",
       " 'taken',\n",
       " 'rply',\n",
       " 'styling',\n",
       " 'sathy',\n",
       " 'cres',\n",
       " 'xxx',\n",
       " 'genus',\n",
       " 'wicklow',\n",
       " 'limping',\n",
       " 'gud',\n",
       " 'scared',\n",
       " 'march',\n",
       " 'really',\n",
       " 'post',\n",
       " 'hip',\n",
       " 'intha',\n",
       " 'fails',\n",
       " 'cosign',\n",
       " 'dont',\n",
       " '5k',\n",
       " 'announcement',\n",
       " 'bears',\n",
       " 'said',\n",
       " 'txt43',\n",
       " 'feeling',\n",
       " 'spouse',\n",
       " 'nah',\n",
       " '60',\n",
       " 'showrooms',\n",
       " 'bari',\n",
       " '54',\n",
       " 'suite',\n",
       " 'super',\n",
       " '87077',\n",
       " 'close',\n",
       " '08702490080',\n",
       " 'nigeria',\n",
       " 'sozi',\n",
       " 'gift',\n",
       " 'hug',\n",
       " 'shopping',\n",
       " 'cumin',\n",
       " 'bw',\n",
       " 'installing',\n",
       " 'dizzamn',\n",
       " 'already',\n",
       " 'agree',\n",
       " '28th',\n",
       " 'perform',\n",
       " 'dating',\n",
       " 'transcribing',\n",
       " 'handed',\n",
       " 'officially',\n",
       " 'jason',\n",
       " 'sometext',\n",
       " 'difficult',\n",
       " 'wnevr',\n",
       " 'drugs',\n",
       " 'wings',\n",
       " 'mind',\n",
       " 'undrstnd',\n",
       " 'gbp',\n",
       " 'crucial',\n",
       " 'car',\n",
       " 'suppose',\n",
       " 'support',\n",
       " 'answering',\n",
       " 'takecare',\n",
       " 'stuck',\n",
       " 'greetings',\n",
       " 'unknown',\n",
       " 'knew',\n",
       " 'flirt',\n",
       " 'managed',\n",
       " 'asshole',\n",
       " 'grace',\n",
       " 'cashto',\n",
       " 'grasp',\n",
       " 'made',\n",
       " 'yellow',\n",
       " 'miserable',\n",
       " 'quizclub',\n",
       " 'company',\n",
       " 'leh',\n",
       " 'hurry',\n",
       " 'shanghai',\n",
       " 'everyday',\n",
       " 'remember',\n",
       " 'past',\n",
       " 'eh',\n",
       " 'hrs',\n",
       " 'emigrated',\n",
       " 'such',\n",
       " 'pansy',\n",
       " 'beware',\n",
       " 'blastin',\n",
       " '80122300p',\n",
       " 'awarded',\n",
       " 'wk',\n",
       " 'usher',\n",
       " '3lp',\n",
       " 'shant',\n",
       " 'ag',\n",
       " 'ball',\n",
       " 'reminding',\n",
       " 'sorted',\n",
       " 'eyed',\n",
       " 'nope',\n",
       " 'spent',\n",
       " 'feelingood',\n",
       " 'den',\n",
       " 'wise',\n",
       " 'walking',\n",
       " 'map',\n",
       " 'mmmmmmm',\n",
       " 'lyricalladie',\n",
       " 'bro',\n",
       " 'bettersn',\n",
       " 'lovejen',\n",
       " 'hot',\n",
       " '09095350301',\n",
       " 'away',\n",
       " 'payed2day',\n",
       " '07880867867',\n",
       " 'form',\n",
       " 'set',\n",
       " 'ntwk',\n",
       " 'married',\n",
       " 'aeronautics',\n",
       " 'shaping',\n",
       " 'urination',\n",
       " 'sooner',\n",
       " 'telling',\n",
       " 'wasn',\n",
       " 'deposit',\n",
       " 'returns',\n",
       " 'collecting',\n",
       " 'less',\n",
       " 'finishing',\n",
       " 'gauti',\n",
       " 'faded',\n",
       " 'urfeeling',\n",
       " 'shouldn',\n",
       " 'watches',\n",
       " 'pei',\n",
       " 'onam',\n",
       " 'valuing',\n",
       " 'lunchtime',\n",
       " 'y',\n",
       " '30',\n",
       " 'waliking',\n",
       " 'th',\n",
       " 'box334sk38ch',\n",
       " 'smoothly',\n",
       " 'get4an18th',\n",
       " 'bank',\n",
       " 'feathery',\n",
       " 'approved',\n",
       " 'staying',\n",
       " 'grown',\n",
       " '8027',\n",
       " '08709501522',\n",
       " 'got',\n",
       " 'dictionary',\n",
       " 'ip4',\n",
       " 'txting',\n",
       " 'tease',\n",
       " 'atural',\n",
       " 'again',\n",
       " 'hiya',\n",
       " 'swhrt',\n",
       " 'petrol',\n",
       " 'pillows',\n",
       " 'ummifying',\n",
       " 'burgundy',\n",
       " 'lil',\n",
       " 'meanwhile',\n",
       " 'busty',\n",
       " 'hand',\n",
       " 'insha',\n",
       " 'bak',\n",
       " 'story',\n",
       " 'organizer',\n",
       " 'ldnw15h',\n",
       " 'quiteamuzing',\n",
       " 'usually',\n",
       " 'prizeawaiting',\n",
       " 'aft',\n",
       " 'asks',\n",
       " 'holla',\n",
       " 'ful',\n",
       " 'disconnect',\n",
       " 'questions',\n",
       " 'tablets',\n",
       " 'nokia6600',\n",
       " 'along',\n",
       " 'previous',\n",
       " 'samachara',\n",
       " 'clubzed',\n",
       " 'attracts',\n",
       " 'cheers',\n",
       " '0871277810910p',\n",
       " 'favourite',\n",
       " 'machines',\n",
       " 'style',\n",
       " 'w1j',\n",
       " 'oi',\n",
       " 'copy',\n",
       " 'xy',\n",
       " 'chart',\n",
       " 'especially',\n",
       " 'interested',\n",
       " 'loan',\n",
       " 'garage',\n",
       " 'gate',\n",
       " '04',\n",
       " 'fantastic',\n",
       " 'dis',\n",
       " 'jokin',\n",
       " 'tlk',\n",
       " 'ou',\n",
       " 'posts',\n",
       " 'buff',\n",
       " 'passport',\n",
       " '2',\n",
       " 'oblivious',\n",
       " 'bakrid',\n",
       " 'write',\n",
       " 'smiling',\n",
       " 'built',\n",
       " '4a',\n",
       " 'screen',\n",
       " 'predicting',\n",
       " 'thus',\n",
       " 'stuff42moro',\n",
       " 'si',\n",
       " 'registered',\n",
       " 'praying',\n",
       " 'ileave',\n",
       " 'evng',\n",
       " 'yup',\n",
       " 'hopefully',\n",
       " 'stash',\n",
       " 'anywhere',\n",
       " 'concentrate',\n",
       " 'raping',\n",
       " '83383',\n",
       " 'henry',\n",
       " 'whom',\n",
       " 'member',\n",
       " 'ringtone',\n",
       " 'vibrator',\n",
       " 'categories',\n",
       " 'prince',\n",
       " 'min',\n",
       " 'question',\n",
       " 'most',\n",
       " 'max6',\n",
       " 'arent',\n",
       " 'porridge',\n",
       " 'blessings',\n",
       " 'mentionned',\n",
       " 'dogging',\n",
       " 'responsibility',\n",
       " 'knock',\n",
       " 'reformat',\n",
       " 'bill',\n",
       " 'ready',\n",
       " '9758',\n",
       " 'allah',\n",
       " 'njan',\n",
       " 'hubby',\n",
       " 'purchase',\n",
       " 'max10mins',\n",
       " '1956669',\n",
       " '8',\n",
       " 'ps3',\n",
       " '01223585334',\n",
       " 'hallaq',\n",
       " 'coz',\n",
       " 'yahoo',\n",
       " 'plan',\n",
       " 'phne',\n",
       " '050703',\n",
       " 'belong',\n",
       " 'msging',\n",
       " 'okie',\n",
       " 'phone750',\n",
       " 'hun',\n",
       " 'booked',\n",
       " 'stoners',\n",
       " 'works',\n",
       " 'forth',\n",
       " 'nursery',\n",
       " '89034',\n",
       " 'kind',\n",
       " 'ranju',\n",
       " 'strewn',\n",
       " '1winaweek',\n",
       " 'wishes',\n",
       " 'applyed',\n",
       " 'distract',\n",
       " 'freephone',\n",
       " 'pick',\n",
       " 'favor',\n",
       " 'serious',\n",
       " 'maintain',\n",
       " 'everyso',\n",
       " 'sudden',\n",
       " 'fruit',\n",
       " 'dbuk',\n",
       " 'ah',\n",
       " 'book',\n",
       " 'are',\n",
       " '03',\n",
       " 'wer',\n",
       " 'quoting',\n",
       " 'lay',\n",
       " 'coincidence',\n",
       " '15',\n",
       " 'pictures',\n",
       " 'official',\n",
       " 'days',\n",
       " 'callcost',\n",
       " 'dual',\n",
       " 'kids',\n",
       " 'hypotheticalhuagauahahuagahyuhagga',\n",
       " 'ccna',\n",
       " 'mostly',\n",
       " 'request',\n",
       " 'toledo',\n",
       " 'tooo',\n",
       " 'dirt',\n",
       " 'eating',\n",
       " 'whether',\n",
       " 'pendent',\n",
       " 'fingers',\n",
       " 'up4',\n",
       " '09061743811',\n",
       " 'great',\n",
       " 'ave',\n",
       " 'quality',\n",
       " 'info',\n",
       " 'eggs',\n",
       " 'treacle',\n",
       " 'goss',\n",
       " 'jst',\n",
       " 'trip',\n",
       " 'neither',\n",
       " 'secure',\n",
       " 'massive',\n",
       " 'co',\n",
       " 'waking',\n",
       " 'gong',\n",
       " 'drinkin',\n",
       " 'fm',\n",
       " 'bids',\n",
       " 'vote',\n",
       " '08715205273',\n",
       " 'salam',\n",
       " 'jen',\n",
       " 'as',\n",
       " 'bite',\n",
       " 'sittin',\n",
       " '49557',\n",
       " 'apologise',\n",
       " 'recognises',\n",
       " 'accumulation',\n",
       " 'beth',\n",
       " 'private',\n",
       " 'simply',\n",
       " 'bowl',\n",
       " 'mike',\n",
       " 'because',\n",
       " 'disclose',\n",
       " 'heading',\n",
       " 'affairs',\n",
       " 'xin',\n",
       " 'dl',\n",
       " 'snow',\n",
       " 'hdd',\n",
       " 'arcade',\n",
       " 'citylink',\n",
       " 'org',\n",
       " 'urawinner',\n",
       " 'unsold',\n",
       " 'bergkamp',\n",
       " 'vodka',\n",
       " 'bored',\n",
       " 'unsubscribe',\n",
       " 'wah',\n",
       " 'exam',\n",
       " 'no',\n",
       " 'solved',\n",
       " 'someone',\n",
       " 'imp',\n",
       " 'lot',\n",
       " '45pm',\n",
       " '87066',\n",
       " 'print',\n",
       " 'filling',\n",
       " 'children',\n",
       " 'angry',\n",
       " 'rooms',\n",
       " 'ipad',\n",
       " 'textpod',\n",
       " 'begin',\n",
       " 'unless',\n",
       " 'savamob',\n",
       " 'hols',\n",
       " 'landlines',\n",
       " 'slowly',\n",
       " 'hollalater',\n",
       " 'truth',\n",
       " 'textand',\n",
       " 'possession',\n",
       " 'reckon',\n",
       " 'hall',\n",
       " 'morning',\n",
       " 'happend',\n",
       " 'breathe',\n",
       " '09061701461',\n",
       " 'fourth',\n",
       " 'two',\n",
       " 'conform',\n",
       " '08002988890',\n",
       " 'nbme',\n",
       " '250',\n",
       " 'depressed',\n",
       " 'spoil',\n",
       " 'evr',\n",
       " 'purchases',\n",
       " 'flat',\n",
       " 'confidence',\n",
       " 'switch',\n",
       " '20p',\n",
       " 'right',\n",
       " 'wave',\n",
       " 'warm',\n",
       " 'fathima',\n",
       " 'psychologist',\n",
       " 'uptown',\n",
       " 'fantasy',\n",
       " 'airtel',\n",
       " 'process',\n",
       " 'raj',\n",
       " 'stars',\n",
       " 'identifier',\n",
       " 'chrgd',\n",
       " 'depression',\n",
       " 'wondar',\n",
       " 'toshiba',\n",
       " 'sway',\n",
       " 'disasters',\n",
       " 'feng',\n",
       " 'scores',\n",
       " 'stomps',\n",
       " 'computers',\n",
       " 'cafe',\n",
       " '220',\n",
       " 'tell',\n",
       " 'ystrday',\n",
       " 'goin',\n",
       " 'price',\n",
       " 'places',\n",
       " '07946746291',\n",
       " 'shanil',\n",
       " 'surrounded',\n",
       " 'professors',\n",
       " 'wishing',\n",
       " 'sentence',\n",
       " 'wiskey',\n",
       " '2b',\n",
       " 'rudi',\n",
       " 'bandages',\n",
       " 'greet',\n",
       " 'mag',\n",
       " 'welcomes',\n",
       " 'oops',\n",
       " 'keyword',\n",
       " 'age16',\n",
       " 'which',\n",
       " 'tel',\n",
       " 'office',\n",
       " 'we',\n",
       " 'skillgame',\n",
       " 'grahmbell',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now build a dictionary: each word corresponds to a list, which shows how many times this word appeard in the first, second, ...  last text message:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_counts_per_sms = {unique_word:[0]*len(vocabulary) for unique_word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for index, sms in enumerate(spam_train['SMS']):\n",
    "    for word in sms.split():\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the performance, we will deleted keys with only 1 entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>02</th>\n",
       "      <th>0207</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>èn</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 5582 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  00  000  008704050406  0121  01223585236  01223585334  0125698789  02  \\\n",
       "0  0   0    0             0     0            0            0           0   0   \n",
       "1  0   0    0             0     0            0            0           0   0   \n",
       "2  0   0    0             0     0            0            0           0   0   \n",
       "\n",
       "   0207 ...  zealand  zed  zeros  zoom  zouk  èn  é  ü  〨ud  鈥  \n",
       "0     0 ...        0    0      0     0     0   0  0  0    0  0  \n",
       "1     0 ...        0    0      0     0     0   0  0  0    0  0  \n",
       "2     0 ...        0    0      0     0     0   0  0  0    0  0  \n",
       "\n",
       "[3 rows x 5582 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts = pd.DataFrame(word_counts_per_sms)\n",
    "word_counts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The columns are sorted, therefore we see the numbers first. By cleaning columns with only 1 entry, we will change the chances of spam or ham. However, the dataframe takes too much space for the DQ server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>0</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>008704050406</th>\n",
       "      <th>0121</th>\n",
       "      <th>01223585236</th>\n",
       "      <th>01223585334</th>\n",
       "      <th>0125698789</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zed</th>\n",
       "      <th>zeros</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zouk</th>\n",
       "      <th>èn</th>\n",
       "      <th>é</th>\n",
       "      <th>ü</th>\n",
       "      <th>〨ud</th>\n",
       "      <th>鈥</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>although i told u dat i m into baig face watch...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>i want some cock my hubby s away i need a real...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>1 go to write msg 2 put on dictionary mode 3 c...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>she doesnt need any test</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>okie but i scared u say i fat  then u dun wan ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5584 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  0  00  000  \\\n",
       "0   ham  although i told u dat i m into baig face watch...  0   0    0   \n",
       "1  spam  i want some cock my hubby s away i need a real...  0   0    0   \n",
       "2   ham  1 go to write msg 2 put on dictionary mode 3 c...  0   0    0   \n",
       "3   ham                          she doesnt need any test   0   0    0   \n",
       "4   ham  okie but i scared u say i fat  then u dun wan ...  0   0    0   \n",
       "\n",
       "   008704050406  0121  01223585236  01223585334  0125698789 ...  zealand  zed  \\\n",
       "0             0     0            0            0           0 ...        0    0   \n",
       "1             0     0            0            0           0 ...        0    0   \n",
       "2             0     0            0            0           0 ...        0    0   \n",
       "3             0     0            0            0           0 ...        0    0   \n",
       "4             0     0            0            0           0 ...        0    0   \n",
       "\n",
       "   zeros  zoom  zouk  èn  é  ü  〨ud  鈥  \n",
       "0      0     0     0   0  0  0    0  0  \n",
       "1      0     0     0   0  0  0    0  0  \n",
       "2      0     0     0   0  0  0    0  0  \n",
       "3      0     0     0   0  0  0    0  0  \n",
       "4      0     0     0   0  0  0    0  0  \n",
       "\n",
       "[5 rows x 5584 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = pd.concat([spam_train,word_counts],axis = 1)\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes: \n",
    "<p>After cleaning the data, we can now build the spam filter. For Naive Bayes, we will need to know the probability values of these two equations:\n",
    "</p>\n",
    "\n",
    "\n",
    "$\\large{P(Spam|w_1,w_2,...,w_n) \\propto P(Spam)\\dot \\prod^{n} _{i=1}P(w_i|Spam)}$\n",
    "\n",
    "$\\large{P(Ham|w_1,w_2,...,w_n) \\propto P(Ham)\\dot \\prod^{n} _{i=1}P(w_i|Ham)}$\n",
    "\n",
    "<p>For $P(w_i|Spam)$ and $P(w_i|Ham)$, we use the additive smoothing:\n",
    "\n",
    "$P(w_i|Spam) = \\frac{N_{w_i|Spam}+\\alpha}{N_{Spam}+\\alpha\\dot N_{Vocabulary}}$\n",
    "\n",
    "$P(w_i|Ham) = \\frac{N_{w_i|Ham}+\\alpha}{N_{Ham}+\\alpha\\dot N_{Vocabulary}}$\n",
    "\n",
    "<p>Some of the terms in the equations above will have the same value for every message:</p>\n",
    "<ul>\n",
    "<li>P(Spam) and P(Ham)</li>\n",
    "<li>N<sub>Spam</sub>, N<sub>Ham</sub>, and N<sub>Vocabulary</sub></li>\n",
    "</ul>\n",
    "\n",
    "<p> We set the Laplace smoothing $\\alpha=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alpha = 1\n",
    "spam = train_clean[train_clean['Label'] == 'spam'].copy()\n",
    "ham = train_clean[train_clean['Label'] == 'ham'].copy()\n",
    "\n",
    "p_spam = spam.shape[0]/train_clean.shape[0]\n",
    "p_ham = ham.shape[0]/train_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_spam = spam['SMS'].apply(len).sum()\n",
    "n_ham = ham['SMS'].apply(len).sum()\n",
    "n_voc = len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.060193479039770695, 0.3697599426728771, 44859, 142651]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[p_spam,p_ham,n_spam,n_ham]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words_spam = {word:0 for word in vocabulary}\n",
    "words_ham = {word:0 for word in vocabulary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spam_train = train_clean[train_clean['Label'] == 'spam'].copy()\n",
    "ham_train = train_clean[train_clean['Label'] == 'ham'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for word in vocabulary:\n",
    "\n",
    "    n_w_spam = spam_train[word].sum()    \n",
    "    p_w_spam = (n_w_spam +alpha)/(n_spam+alpha*n_voc)\n",
    "    words_spam[word] = p_w_spam\n",
    "\n",
    "    n_w_ham = ham_train[word].sum()    \n",
    "    p_w_ham = (n_w_ham +alpha)/(n_ham+alpha*n_voc)\n",
    "    words_ham[word] = p_w_ham\n",
    "\n",
    " \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying a message\n",
    "<p>We can now start to create the spam filter. It should be a function that:</p>\n",
    "<ul>\n",
    "<li> Takes in as input a new message $(w_1,w_2,\\dots w_n$</li>\n",
    "<li> Calulates $P(Spam|w_1,w_2,\\dots w_n)$ and $P(Ham|w_1,w_2,\\dots w_n)$</li>\n",
    "<li> Compares the values $P(Spam|w_1,w_2,\\dots w_n)$ and $P(Ham|w_1,w_2,\\dots w_n)$ and </li>\n",
    "<ul>\n",
    "<li> If $P(Ham|w_1,w_2,\\dots w_n)$ > $P(Spam|w_1,w_2,\\dots w_n)$: classify the message as ham</li>\n",
    "<li> If $P(Spam|w_1,w_2,\\dots w_n)$ > $P(Ham|w_1,w_2,\\dots w_n)$: classify the message as spam</li>\n",
    "<li> If $P(Spam|w_1,w_2,\\dots w_n)$ = $P(Ham|w_1,w_2,\\dots w_n)$: undecided and we might need to think of something.</li>\n",
    "</ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classify(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    \n",
    "    for word in message:\n",
    "        if word in words_spam:\n",
    "            p_spam_given_message *= words_spam[word]\n",
    "        if word in words_ham:\n",
    "            p_ham_given_message *= words_ham[word]    \n",
    "    \n",
    "\n",
    "    print('P(Spam|message):', p_spam_given_message)\n",
    "    print('P(Ham|message):', p_ham_given_message)\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        print('Label: Ham')\n",
    "    elif p_ham_given_message < p_spam_given_message:\n",
    "        print('Label: Spam')\n",
    "    else:\n",
    "        print('Equal proabilities, have a human classify this!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 3.257402590719452e-31\n",
      "P(Ham|message): 4.6195127319809316e-33\n",
      "Label: Spam\n"
     ]
    }
   ],
   "source": [
    "classify('WINNER!! This is the secret code to unlock the money: C3421.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(Spam|message): 2.9578706974653834e-29\n",
      "P(Ham|message): 2.0537815380623668e-25\n",
      "Label: Ham\n"
     ]
    }
   ],
   "source": [
    "classify(\"Sounds good, Tom, then see u there\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we test the spam filter on the test set. First, we need to rewrite the classify function to use it on the test data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify_test_set(message):\n",
    "\n",
    "    message = re.sub('\\W', ' ', message)\n",
    "    message = message.lower()\n",
    "    message = message.split()\n",
    "\n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "\n",
    "    for word in message:\n",
    "        if word in words_spam:\n",
    "            p_spam_given_message *= words_spam[word]\n",
    "\n",
    "        if word in words_ham:\n",
    "            p_ham_given_message *= words_ham[word]\n",
    "\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Where wuld I be without my baby? The thought a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Dear Voucher Holder, 2 claim this weeks offer,...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>But you dint in touch with me.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hai priya are you right. What doctor said pa. ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>K come to nordstrom when you're done</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS predicted\n",
       "0   ham  Where wuld I be without my baby? The thought a...       ham\n",
       "1  spam  Dear Voucher Holder, 2 claim this weeks offer,...      spam\n",
       "2   ham                     But you dint in touch with me.       ham\n",
       "3   ham  Hai priya are you right. What doctor said pa. ...       ham\n",
       "4   ham               K come to nordstrom when you're done       ham"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_test['predicted'] = spam_test['SMS'].apply(classify_test_set)\n",
    "spam_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now look at the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9833333333333333"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(spam_test['Label'] == spam_test['predicted']).sum()/spam_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a good accuracy. Next, we'll look at the messages that have been categorised incorrectly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>spam</td>\n",
       "      <td>LookAtMe!: Thanks for your purchase of a video...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>spam</td>\n",
       "      <td>LIFE has never been this much fun and great un...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Jordan, how r u? Im home from abro...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>ham</td>\n",
       "      <td>Waiting for your call.</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>ham</td>\n",
       "      <td>We have sent JD for Customer Service cum Accou...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>spam</td>\n",
       "      <td>Hi babe its Chloe, how r u? I was smashed on s...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>spam</td>\n",
       "      <td>TBS/PERSOLVO. been chasing us since Sept for£3...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>spam</td>\n",
       "      <td>Did you hear about the new \"Divorce Barbie\"? I...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>ham</td>\n",
       "      <td>For me the love should start with attraction.i...</td>\n",
       "      <td>needs human classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>ham</td>\n",
       "      <td>Gettin rdy to ship comp</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Label                                                SMS  \\\n",
       "157  spam  LookAtMe!: Thanks for your purchase of a video...   \n",
       "202  spam  LIFE has never been this much fun and great un...   \n",
       "263  spam  Hi babe its Jordan, how r u? Im home from abro...   \n",
       "264   ham                             Waiting for your call.   \n",
       "275   ham  We have sent JD for Customer Service cum Accou...   \n",
       "280  spam  Hi babe its Chloe, how r u? I was smashed on s...   \n",
       "330  spam  TBS/PERSOLVO. been chasing us since Sept for£3...   \n",
       "359  spam  Did you hear about the new \"Divorce Barbie\"? I...   \n",
       "494   ham  For me the love should start with attraction.i...   \n",
       "516   ham                            Gettin rdy to ship comp   \n",
       "\n",
       "                      predicted  \n",
       "157                         ham  \n",
       "202                         ham  \n",
       "263                         ham  \n",
       "264                        spam  \n",
       "275                        spam  \n",
       "280                         ham  \n",
       "330                         ham  \n",
       "359                         ham  \n",
       "494  needs human classification  \n",
       "516                        spam  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_test[spam_test['Label'] != spam_test['predicted']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The messages that got categorised incorrectly, do not display a \"typical\" spam jargon, which makes it difficult for the algorithm to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "<p>We build a spam filter using Naive Bayes. We used this <a href = \"https://archive.ics.uci.edu/ml/datasets/sms+spam+collection\">data set</a> containing numerous SMS messages, which have been already classified into spam and ham. Splitting the data set into a test and train set, we cleaned the train set and computed the probabilities of each word to appear in a spam or ham message. Using these probabilities, we were able to classify the SMS messages from the test set with an accuracy of "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
